{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 8. Линейные методы. Vowpal Wabbit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vowpal Wabbit on GitHub: https://github.com/JohnLangford/vowpal_wabbit\n",
    "\n",
    "Vowpal Wabbit Tutorial: https://github.com/JohnLangford/vowpal_wabbit/wiki/Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = '../Contests/contest1_stackoverflow/train-contest.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PostId</th>\n",
       "      <th>PostCreationDate</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>OwnerCreationDate</th>\n",
       "      <th>ReputationAtPostCreation</th>\n",
       "      <th>OwnerUndeletedAnswerCountAtPostTime</th>\n",
       "      <th>Title</th>\n",
       "      <th>BodyMarkdown</th>\n",
       "      <th>Tag1</th>\n",
       "      <th>Tag2</th>\n",
       "      <th>Tag3</th>\n",
       "      <th>Tag4</th>\n",
       "      <th>Tag5</th>\n",
       "      <th>PostClosedDate</th>\n",
       "      <th>OpenStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11385967</td>\n",
       "      <td>07/08/2012 19:23:47</td>\n",
       "      <td>109676</td>\n",
       "      <td>04/27/2009 18:56:57</td>\n",
       "      <td>2382</td>\n",
       "      <td>81</td>\n",
       "      <td>Converting VB.NET Web Form to C# and wiring up...</td>\n",
       "      <td>In My VB.NET web page, I have this standard ev...</td>\n",
       "      <td>c#</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11351831</td>\n",
       "      <td>07/05/2012 20:09:03</td>\n",
       "      <td>1160891</td>\n",
       "      <td>01/20/2012 15:14:57</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>How to install visual studio 2010 in alternate...</td>\n",
       "      <td>I'm trying to install VS 2010 on D drive, but ...</td>\n",
       "      <td>visual-studio-2010</td>\n",
       "      <td>installation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6411162</td>\n",
       "      <td>06/20/2011 12:30:47</td>\n",
       "      <td>706293</td>\n",
       "      <td>04/13/2011 15:02:59</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>Advise on resources where to learn IT Infrastr...</td>\n",
       "      <td>My IT knowledge resides mainly in SW developme...</td>\n",
       "      <td>documentation</td>\n",
       "      <td>tutorials</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06/20/2011 23:25:56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9962611</td>\n",
       "      <td>04/01/2012 07:16:03</td>\n",
       "      <td>168143</td>\n",
       "      <td>09/03/2009 20:31:24</td>\n",
       "      <td>3052</td>\n",
       "      <td>102</td>\n",
       "      <td>How is my single-threaded Rails app handling c...</td>\n",
       "      <td>I have a single-threaded Rails app running on ...</td>\n",
       "      <td>ruby-on-rails</td>\n",
       "      <td>ruby</td>\n",
       "      <td>concurrency</td>\n",
       "      <td>heroku</td>\n",
       "      <td>rack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11361230</td>\n",
       "      <td>07/06/2012 11:21:17</td>\n",
       "      <td>1047058</td>\n",
       "      <td>11/15/2011 07:34:27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>picturebox not showing anything in wndproc \"ho...</td>\n",
       "      <td>im trying to show printscreen image in picture...</td>\n",
       "      <td>c#</td>\n",
       "      <td>api</td>\n",
       "      <td>picturebox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PostId     PostCreationDate  OwnerUserId    OwnerCreationDate  \\\n",
       "0  11385967  07/08/2012 19:23:47       109676  04/27/2009 18:56:57   \n",
       "1  11351831  07/05/2012 20:09:03      1160891  01/20/2012 15:14:57   \n",
       "2   6411162  06/20/2011 12:30:47       706293  04/13/2011 15:02:59   \n",
       "3   9962611  04/01/2012 07:16:03       168143  09/03/2009 20:31:24   \n",
       "4  11361230  07/06/2012 11:21:17      1047058  11/15/2011 07:34:27   \n",
       "\n",
       "   ReputationAtPostCreation  OwnerUndeletedAnswerCountAtPostTime  \\\n",
       "0                      2382                                   81   \n",
       "1                        32                                    0   \n",
       "2                        21                                    2   \n",
       "3                      3052                                  102   \n",
       "4                         1                                    0   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Converting VB.NET Web Form to C# and wiring up...   \n",
       "1  How to install visual studio 2010 in alternate...   \n",
       "2  Advise on resources where to learn IT Infrastr...   \n",
       "3  How is my single-threaded Rails app handling c...   \n",
       "4  picturebox not showing anything in wndproc \"ho...   \n",
       "\n",
       "                                        BodyMarkdown                Tag1  \\\n",
       "0  In My VB.NET web page, I have this standard ev...                  c#   \n",
       "1  I'm trying to install VS 2010 on D drive, but ...  visual-studio-2010   \n",
       "2  My IT knowledge resides mainly in SW developme...       documentation   \n",
       "3  I have a single-threaded Rails app running on ...       ruby-on-rails   \n",
       "4  im trying to show printscreen image in picture...                  c#   \n",
       "\n",
       "           Tag2         Tag3    Tag4  Tag5       PostClosedDate  OpenStatus  \n",
       "0           NaN          NaN     NaN   NaN                  NaN           0  \n",
       "1  installation          NaN     NaN   NaN                  NaN           0  \n",
       "2     tutorials    knowledge     NaN   NaN  06/20/2011 23:25:56           1  \n",
       "3          ruby  concurrency  heroku  rack                  NaN           0  \n",
       "4           api   picturebox     NaN   NaN                  NaN           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(train_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "I have a global variable called 'name', when a user clicks on a button a text boxes content is queried and 'name' is set to the contents then the name gets printed in a different jquery page.\r\n",
      "\r\n",
      "My problem is name is never printed as the name it was set to, it's always printed as what it was initially set to instead.\r\n",
      "\r\n",
      "Here's my callback function:\r\n",
      "\r\n",
      "\t\t<script type=\"text/javascript\">\r\n",
      "\t\t\t$(\"#finalize\").click(function(e)\r\n",
      "\t\t\t{\r\n",
      "\t\t\t\tg_name = \"BLAH\";\r\n",
      "\t\t\t\treturn true;\r\n",
      "\t\t\t});\r\n",
      "\t\t</script>\r\n",
      "\r\n",
      "For simplicity I've set the name to just be 'BLAH' on the click.\r\n",
      "\r\n",
      "g_name is declared globally (i.e. outside the function scope).\r\n",
      "\r\n",
      "In the other jquery page I have:\r\n",
      "\r\n",
      "    document.write('<label for=\"testname\">Name:</label>');\r\n",
      "    \t\t\t\tdocument.write('<input type=\"text\" name=\"testname\" id=\"testname\" value=\"');\r\n",
      "    \t\t\t\tdocument.write(g_name)\r\n",
      "    \t\t\t\tdocument.write('\"/>');\r\n",
      "\r\n",
      "And g_name is always shown as something else, whatever g_name was initially initilized to.\r\n",
      "\r\n",
      "The button whose click callback sets the global variable also transitions the pages if that makes a difference...\n"
     ]
    }
   ],
   "source": [
    "print data.OpenStatus[10]\n",
    "print data.BodyMarkdown[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = data.iloc[:50000, :]\n",
    "data_test = data.iloc[70000:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def save_to_vw(data, fname):\n",
    "    with open(fname, 'w') as fout:\n",
    "        for _, row in data.iterrows():\n",
    "            text = filter(lambda x: len(x) > 1, re.split(\"[^a-z]\",\n",
    "                                    row.BodyMarkdown.lower()))\n",
    "            text = ' '.join(text)\n",
    "            if row.OpenStatus == 1:\n",
    "                target = 1\n",
    "            else:\n",
    "                target = -1\n",
    "            fout.write('{0} |n 0:{1} {2} |t {3}\\n'.format(target, \n",
    "                                        row.ReputationAtPostCreation,\n",
    "                                        row.Tag1,\n",
    "                                        text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_to_vw(data_train, 'train.vw')\n",
    "save_to_vw(data_test, 'test.vw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 |n 0:2382 c# |t in my vb net web page have this standard event note the handles clause on teh event declaration protected sub page load byval sender as object byval as system eventargs handles me load end sub in my web app have this protected void page load object sender system eventargs since doesn have handles equivalent and from what ve seen event handlers are wired up using delegate syntax was looking for this but could not foind it in the aspx page aspx cs file or the aspx designer cs file in vb would have two drop down lists at the top of the code editor window and could select any object on the web form or the web form itself and see the possible events for the object selecting the event would either take me to the event handler or if it didn exists it would create the stub for me know that the properties window in and think in vb too has an event tab that shows the list of events for the selected object gui object but page doesn appear as an object that can be selected where does define the hooking up of the event to the handler how do generate stub for the page event handler routine know that the handle appears by default but what if it is deleted or want to add page initialize code is there an easy way to get the stub or do need to go to the object browser for the syntax\r\n",
      "-1 |n 0:32 visual-studio-2010 |t trying to install vs on drive but when change the location in the destination field of the installer it doesn matter it still installs it on the only thing that went to was the install log file any way around this\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 train.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = train.vw.cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "1.000000   1.000000          1      1.0    -1.0000   0.0000      254\n",
      "0.763886   0.527772          2      2.0    -1.0000  -0.2735       44\n",
      "1.590055   2.416223          4      4.0    -1.0000  -0.0876       82\n",
      "1.230513   0.870972          8      8.0     1.0000  -0.2551       77\n",
      "0.712284   0.194056         16     16.0    -1.0000  -0.6717      190\n",
      "0.773382   0.834480         32     32.0     1.0000   0.0282       21\n",
      "0.963355   1.153328         64     64.0     1.0000   0.4354      100\n",
      "0.971244   0.979133        128    128.0     1.0000   0.1124       52\n",
      "1.004249   1.037254        256    256.0    -1.0000   0.2181      279\n",
      "0.961495   0.918740        512    512.0    -1.0000  -1.0000      353\n",
      "0.969954   0.978414       1024   1024.0    -1.0000  -1.0000      187\n",
      "0.932470   0.894986       2048   2048.0    -1.0000  -0.2209       90\n",
      "0.900172   0.867874       4096   4096.0    -1.0000   0.3188       45\n",
      "0.887369   0.874567       8192   8192.0    -1.0000  -0.1425       59\n",
      "0.857357   0.827344      16384  16384.0    -1.0000  -0.9587      144\n",
      "0.831259   0.805162      32768  32768.0     1.0000  -0.3441       61\n",
      "0.820637   0.820637      65536  65536.0     1.0000   0.0138       14 h\n",
      "0.800908   0.781181     131072 131072.0    -1.0000  -0.2579      156 h\n",
      "0.796747   0.792586     262144 262144.0     1.0000   1.0000       98 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 45000\n",
      "passes used = 6\n",
      "weighted example sum = 270000\n",
      "weighted label sum = 804\n",
      "average loss = 0.782696 h\n",
      "best constant = 0.00297778\n",
      "best constant's loss = 0.999991\n",
      "total feature number = 29599188\n"
     ]
    }
   ],
   "source": [
    "!vw -d train.vw -c -k -f model.vw --passes 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = pred.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 10\n",
      "initial_t = 1\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "1.152298   1.152298          1      1.0    -1.0000   0.0735       63\n",
      "1.548524   1.944750          2      2.0    -1.0000   0.3945       31\n",
      "1.304907   1.061290          4      4.0     1.0000  -0.3451      103\n",
      "0.919371   0.533836          8      8.0     1.0000   0.7522       33\n",
      "0.708812   0.498253         16     16.0    -1.0000  -1.0000      139\n",
      "0.694174   0.679535         32     32.0     1.0000   0.0276      154\n",
      "0.757704   0.821234         64     64.0     1.0000  -0.3299       36\n",
      "0.843794   0.929883        128    128.0     1.0000   1.0000      108\n",
      "0.821948   0.800103        256    256.0     1.0000   0.4271       30\n",
      "0.818219   0.814491        512    512.0     1.0000   0.5219       16\n",
      "0.809796   0.801373       1024   1024.0     1.0000  -0.1509       36\n",
      "0.830346   0.850896       2048   2048.0     1.0000  -0.8936      143\n",
      "0.809417   0.788487       4096   4096.0     1.0000   0.4111       73\n",
      "0.808486   0.807555       8192   8192.0     1.0000   0.7119       57\n",
      "0.807379   0.806271      16384  16384.0     1.0000  -0.1052       73\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 30000\n",
      "passes used = 1\n",
      "weighted example sum = 30000\n",
      "weighted label sum = -36\n",
      "average loss = 0.808094\n",
      "best constant = -0.0012\n",
      "best constant's loss = 0.999999\n",
      "total feature number = 3282780\n"
     ]
    }
   ],
   "source": [
    "!vw -d test.vw -i model.vw -t -p pred.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.073451\r\n",
      "0.394543\r\n",
      "-0.440162\r\n",
      "-0.345051\r\n",
      "1.000000\r\n",
      "0.707419\r\n",
      "-0.410080\r\n",
      "0.752177\r\n",
      "0.555422\r\n",
      "0.082952\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 pred.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def calc_vw_qual():\n",
    "    preds = pd.read_csv('pred.txt', header=None).iloc[:, 0].values\n",
    "    target = data_test.OpenStatus.values\n",
    "    print roc_auc_score(target, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773175444484\n"
     ]
    }
   ],
   "source": [
    "calc_vw_qual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.1\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = train.vw.cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "1.000000   1.000000          1      1.0    -1.0000   0.0000      254\n",
      "0.824177   0.648353          2      2.0    -1.0000  -0.1948       44\n",
      "1.239373   1.654570          4      4.0    -1.0000  -0.1296       82\n",
      "1.074697   0.910021          8      8.0     1.0000  -0.2473       77\n",
      "0.666821   0.258945         16     16.0    -1.0000  -0.5618      190\n",
      "0.758021   0.849221         32     32.0     1.0000  -0.0742       21\n",
      "0.889370   1.020718         64     64.0     1.0000   0.2461      100\n",
      "0.948542   1.007714        128    128.0     1.0000  -0.0434       52\n",
      "0.957862   0.967181        256    256.0    -1.0000   0.1023      279\n",
      "0.921585   0.885309        512    512.0    -1.0000  -1.0000      353\n",
      "0.908468   0.895350       1024   1024.0    -1.0000  -0.7613      187\n",
      "0.887433   0.866398       2048   2048.0    -1.0000   0.1988       90\n",
      "0.852034   0.816636       4096   4096.0    -1.0000   0.0822       45\n",
      "0.834252   0.816469       8192   8192.0    -1.0000   0.0127       59\n",
      "0.811368   0.788483      16384  16384.0    -1.0000  -0.2257      144\n",
      "0.790321   0.769275      32768  32768.0     1.0000  -0.2730       61\n",
      "0.774243   0.774243      65536  65536.0     1.0000  -0.0104       14 h\n",
      "0.756725   0.739209     131072 131072.0    -1.0000  -0.2226      156 h\n",
      "0.748719   0.740713     262144 262144.0     1.0000   0.4241       98 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 45000\n",
      "passes used = 8\n",
      "weighted example sum = 360000\n",
      "weighted label sum = 1072\n",
      "average loss = 0.737692 h\n",
      "best constant = 0.00297778\n",
      "best constant's loss = 0.999991\n",
      "total feature number = 39465584\n",
      "only testing\n",
      "predictions = pred.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 10\n",
      "initial_t = 1\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "0.967979   0.967979          1      1.0    -1.0000  -0.0161       63\n",
      "1.378386   1.788794          2      2.0    -1.0000   0.3375       31\n",
      "1.150693   0.922999          4      4.0     1.0000  -0.2268      103\n",
      "0.869414   0.588136          8      8.0     1.0000   0.6655       33\n",
      "0.674492   0.479570         16     16.0    -1.0000  -1.0000      139\n",
      "0.693865   0.713238         32     32.0     1.0000  -0.0061      154\n",
      "0.668954   0.644042         64     64.0     1.0000  -0.1212       36\n",
      "0.794765   0.920575        128    128.0     1.0000   0.6855      108\n",
      "0.769672   0.744579        256    256.0     1.0000   0.3604       30\n",
      "0.770227   0.770782        512    512.0     1.0000   0.2394       16\n",
      "0.754286   0.738346       1024   1024.0     1.0000  -0.0295       36\n",
      "0.767919   0.781552       2048   2048.0     1.0000  -0.6225      143\n",
      "0.748460   0.729002       4096   4096.0     1.0000   0.3333       73\n",
      "0.750456   0.752452       8192   8192.0     1.0000   0.4319       57\n",
      "0.751694   0.752933      16384  16384.0     1.0000   0.1781       73\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 30000\n",
      "passes used = 1\n",
      "weighted example sum = 30000\n",
      "weighted label sum = -36\n",
      "average loss = 0.754607\n",
      "best constant = -0.0012\n",
      "best constant's loss = 0.999999\n",
      "total feature number = 3282780\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.795818952646\n"
     ]
    }
   ],
   "source": [
    "!vw -d train.vw -c -k -f model.vw --passes 10 -l 0.1\n",
    "!vw -d test.vw -i model.vw -t -p pred.txt\n",
    "print '\\n\\n\\n'\n",
    "calc_vw_qual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for t namespaces.\n",
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.1\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = train.vw.cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "1.000000   1.000000          1      1.0    -1.0000   0.0000      504\n",
      "0.893775   0.787549          2      2.0    -1.0000  -0.1126       84\n",
      "1.116160   1.338546          4      4.0    -1.0000  -0.0854      160\n",
      "1.027996   0.939831          8      8.0     1.0000  -0.1864      150\n",
      "0.708380   0.388764         16     16.0    -1.0000  -0.4080      376\n",
      "0.781467   0.854553         32     32.0     1.0000  -0.0693       38\n",
      "0.906742   1.032018         64     64.0     1.0000   0.1270      196\n",
      "0.954535   1.002328        128    128.0     1.0000   0.0251      100\n",
      "0.958956   0.963377        256    256.0    -1.0000  -0.0042      554\n",
      "0.924073   0.889190        512    512.0    -1.0000  -0.6464      702\n",
      "0.910840   0.897607       1024   1024.0    -1.0000  -0.5431      370\n",
      "0.882104   0.853368       2048   2048.0    -1.0000   0.1372      176\n",
      "0.844674   0.807245       4096   4096.0    -1.0000   0.0522       86\n",
      "0.822062   0.799450       8192   8192.0    -1.0000   0.0233      114\n",
      "0.796661   0.771259      16384  16384.0    -1.0000  -0.0644      284\n",
      "0.773501   0.750340      32768  32768.0     1.0000  -0.2356      118\n",
      "0.753040   0.753040      65536  65536.0     1.0000   0.0129       24 h\n",
      "0.736569   0.720101     131072 131072.0    -1.0000  -0.5319      308 h\n",
      "0.732677   0.728785     262144 262144.0     1.0000   0.7083      192 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 45000\n",
      "passes used = 6\n",
      "weighted example sum = 270000\n",
      "weighted label sum = 804\n",
      "average loss = 0.722579 h\n",
      "best constant = 0.00297778\n",
      "best constant's loss = 0.999991\n",
      "total feature number = 58118424\n",
      "Generating 2-grams for t namespaces.\n",
      "only testing\n",
      "predictions = pred.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 10\n",
      "initial_t = 1\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "1.595541   1.595541          1      1.0    -1.0000   0.2631      122\n",
      "1.599734   1.603927          2      2.0    -1.0000   0.2665       58\n",
      "1.235688   0.871643          4      4.0     1.0000  -0.1241      202\n",
      "0.930128   0.624568          8      8.0     1.0000   0.5088       62\n",
      "0.703467   0.476807         16     16.0    -1.0000  -1.0000      274\n",
      "0.707816   0.712165         32     32.0     1.0000   0.1980      304\n",
      "0.652686   0.597557         64     64.0     1.0000  -0.1202       68\n",
      "0.723338   0.793989        128    128.0     1.0000   0.3570      212\n",
      "0.718935   0.714532        256    256.0     1.0000   0.4605       56\n",
      "0.744337   0.769738        512    512.0     1.0000   0.2156       28\n",
      "0.730421   0.716506       1024   1024.0     1.0000   0.1639       68\n",
      "0.752214   0.774006       2048   2048.0     1.0000  -0.3549      282\n",
      "0.730550   0.708887       4096   4096.0     1.0000   0.3357      142\n",
      "0.733758   0.736966       8192   8192.0     1.0000   0.1920      110\n",
      "0.732117   0.730475      16384  16384.0     1.0000   0.1737      142\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 30000\n",
      "passes used = 1\n",
      "weighted example sum = 30000\n",
      "weighted label sum = -36\n",
      "average loss = 0.736556\n",
      "best constant = -0.0012\n",
      "best constant's loss = 0.999999\n",
      "total feature number = 6445570\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.804332049349\n"
     ]
    }
   ],
   "source": [
    "!vw -d train.vw -c -k -f model.vw --passes 10 -l 0.1 --ngram t2\n",
    "!vw -d test.vw -i model.vw -t -p pred.txt\n",
    "print '\\n\\n\\n'\n",
    "calc_vw_qual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for t namespaces.\n",
      "Generating 2-skips for t namespaces.\n",
      "final_regressor = model.vw\n",
      "Num weight bits = 18\n",
      "learning rate = 0.1\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = train.vw.cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "1.000000   1.000000          1      1.0    -1.0000   0.0000     1001\n",
      "0.932438   0.864876          2      2.0    -1.0000  -0.0700      161\n",
      "1.069380   1.206322          4      4.0    -1.0000  -0.0552      313\n",
      "1.013547   0.957714          8      8.0     1.0000  -0.1455      293\n",
      "0.764101   0.514655         16     16.0    -1.0000  -0.2995      745\n",
      "0.818270   0.872439         32     32.0     1.0000  -0.0604       69\n",
      "0.933228   1.048186         64     64.0     1.0000   0.0474      385\n",
      "0.968953   1.004679        128    128.0     1.0000   0.0376      193\n",
      "0.972765   0.976577        256    256.0    -1.0000   0.0388     1101\n",
      "0.943197   0.913628        512    512.0    -1.0000  -0.5981     1397\n",
      "0.919806   0.896414       1024   1024.0    -1.0000  -0.5430      733\n",
      "0.885548   0.851291       2048   2048.0    -1.0000   0.1198      345\n",
      "0.850710   0.815872       4096   4096.0    -1.0000   0.0249      165\n",
      "0.826076   0.801441       8192   8192.0    -1.0000  -0.1443      221\n",
      "0.799693   0.773310      16384  16384.0    -1.0000  -0.3139      561\n",
      "0.775771   0.751849      32768  32768.0     1.0000  -0.3094      229\n",
      "0.758062   0.758062      65536  65536.0     1.0000  -0.0434       41 h\n",
      "0.742089   0.726118     131072 131072.0    -1.0000  -0.5691      609 h\n",
      "0.738059   0.734029     262144 262144.0     1.0000   0.5413      377 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 45000\n",
      "passes used = 6\n",
      "weighted example sum = 270000\n",
      "weighted label sum = 804\n",
      "average loss = 0.726407 h\n",
      "best constant = 0.00297778\n",
      "best constant's loss = 0.999991\n",
      "total feature number = 114346926\n",
      "Generating 2-grams for t namespaces.\n",
      "Generating 2-skips for t namespaces.\n",
      "only testing\n",
      "predictions = pred.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 10\n",
      "initial_t = 1\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "1.075945   1.075945          1      1.0    -1.0000   0.0373      237\n",
      "1.128304   1.180664          2      2.0    -1.0000   0.0866      109\n",
      "0.951898   0.775491          4      4.0     1.0000  -0.0827      397\n",
      "0.804043   0.656188          8      8.0     1.0000   0.5205      117\n",
      "0.610966   0.417888         16     16.0    -1.0000  -1.0000      541\n",
      "0.604925   0.598885         32     32.0     1.0000   0.6104      601\n",
      "0.614928   0.624931         64     64.0     1.0000  -0.1581      129\n",
      "0.741834   0.868741        128    128.0     1.0000   0.7399      417\n",
      "0.752590   0.763346        256    256.0     1.0000   0.3112      105\n",
      "0.771693   0.790795        512    512.0     1.0000   0.2330       49\n",
      "0.726910   0.682127       1024   1024.0     1.0000   0.0553      129\n",
      "0.738126   0.749341       2048   2048.0     1.0000  -0.2238      557\n",
      "0.719799   0.701473       4096   4096.0     1.0000   0.4241      277\n",
      "0.731549   0.743300       8192   8192.0     1.0000   0.2187      213\n",
      "0.734376   0.737202      16384  16384.0     1.0000  -0.0125      277\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 30000\n",
      "passes used = 1\n",
      "weighted example sum = 30000\n",
      "weighted label sum = -36\n",
      "average loss = 0.74107\n",
      "best constant = -0.0012\n",
      "best constant's loss = 0.999999\n",
      "total feature number = 12681158\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.801859899123\n"
     ]
    }
   ],
   "source": [
    "!vw -d train.vw -c -k -f model.vw --passes 10 -l 0.1 --ngram t2 --skips t2\n",
    "!vw -d test.vw -i model.vw -t -p pred.txt\n",
    "print '\\n\\n\\n'\n",
    "calc_vw_qual()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2-grams for t namespaces.\n",
      "final_regressor = model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.1\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = train.vw.cache\n",
      "Reading datafile = train.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "1.000000   1.000000          1      1.0    -1.0000   0.0000      504\n",
      "0.893775   0.787549          2      2.0    -1.0000  -0.1126       84\n",
      "1.116160   1.338546          4      4.0    -1.0000  -0.0854      160\n",
      "1.027811   0.939461          8      8.0     1.0000  -0.1863      150\n",
      "0.709204   0.390598         16     16.0    -1.0000  -0.4044      376\n",
      "0.781565   0.853925         32     32.0     1.0000  -0.0694       38\n",
      "0.907234   1.032904         64     64.0     1.0000   0.1415      196\n",
      "0.956017   1.004799        128    128.0     1.0000   0.0238      100\n",
      "0.958802   0.961587        256    256.0    -1.0000   0.0139      554\n",
      "0.922804   0.886807        512    512.0    -1.0000  -0.7178      702\n",
      "0.905882   0.888960       1024   1024.0    -1.0000  -0.5005      370\n",
      "0.880956   0.856031       2048   2048.0    -1.0000   0.1201      176\n",
      "0.844209   0.807462       4096   4096.0    -1.0000   0.0523       86\n",
      "0.820686   0.797162       8192   8192.0    -1.0000  -0.0168      114\n",
      "0.793368   0.766050      16384  16384.0    -1.0000  -0.0548      284\n",
      "0.769386   0.745404      32768  32768.0     1.0000  -0.2470      118\n",
      "0.749056   0.749056      65536  65536.0     1.0000   0.0382       24 h\n",
      "0.733060   0.717067     131072 131072.0    -1.0000  -0.6721      308 h\n",
      "0.728503   0.723947     262144 262144.0     1.0000   0.8244      192 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 45000\n",
      "passes used = 6\n",
      "weighted example sum = 270000\n",
      "weighted label sum = 804\n",
      "average loss = 0.719192 h\n",
      "best constant = 0.00297778\n",
      "best constant's loss = 0.999991\n",
      "total feature number = 58118424\n",
      "Generating 2-grams for t namespaces.\n",
      "only testing\n",
      "predictions = pred.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 10\n",
      "initial_t = 1\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test.vw\n",
      "num sources = 1\n",
      "average    since         example     example  current  current  current\n",
      "loss       last          counter      weight    label  predict features\n",
      "1.528964   1.528964          1      1.0    -1.0000   0.2365      122\n",
      "1.474457   1.419949          2      2.0    -1.0000   0.1916       58\n",
      "1.170484   0.866511          4      4.0     1.0000  -0.0688      202\n",
      "0.862293   0.554103          8      8.0     1.0000   0.5509       62\n",
      "0.655119   0.447944         16     16.0    -1.0000  -1.0000      274\n",
      "0.656102   0.657085         32     32.0     1.0000   0.3464      304\n",
      "0.609882   0.563662         64     64.0     1.0000  -0.1478       68\n",
      "0.705051   0.800220        128    128.0     1.0000   0.2052      212\n",
      "0.726815   0.748580        256    256.0     1.0000   0.5054       56\n",
      "0.746268   0.765720        512    512.0     1.0000   0.2483       28\n",
      "0.724153   0.702038       1024   1024.0     1.0000   0.1363       68\n",
      "0.741659   0.759165       2048   2048.0     1.0000  -0.4011      282\n",
      "0.726282   0.710906       4096   4096.0     1.0000   0.1970      142\n",
      "0.727402   0.728522       8192   8192.0     1.0000   0.2676      110\n",
      "0.725920   0.724438      16384  16384.0     1.0000   0.3147      142\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 30000\n",
      "passes used = 1\n",
      "weighted example sum = 30000\n",
      "weighted label sum = -36\n",
      "average loss = 0.730816\n",
      "best constant = -0.0012\n",
      "best constant's loss = 0.999999\n",
      "total feature number = 6445570\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "0.809787454983\n"
     ]
    }
   ],
   "source": [
    "!vw -d train.vw -c -k -f model.vw --passes 10 -l 0.1 --ngram t2 -b 28\n",
    "!vw -d test.vw -i model.vw -t -p pred.txt\n",
    "print '\\n\\n\\n'\n",
    "calc_vw_qual()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
